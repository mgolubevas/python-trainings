{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "satisfactory-valuation",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Join Merge and Concatenate](02-join-merge-and-concatenate.ipynb) | [Contents](Index.ipynb) | [More Operation on Dataframe](04-more-operation-on-dataframe.ipynb) >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-huntington",
   "metadata": {},
   "source": [
    "## Data cleaning and handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-recovery",
   "metadata": {},
   "source": [
    "Here you will learn basics how to clean data and to handle missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-piece",
   "metadata": {},
   "source": [
    "To be able to test the functions, lets import a dataframe from dwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../Data/airlineDT.csv', sep=',')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-budapest",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-canal",
   "metadata": {},
   "source": [
    "Next part is to prepare a data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-wellington",
   "metadata": {},
   "source": [
    "There are multiple ways to select row or column of the given dataframe. Here you can select a specific column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DEP_TIME']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-reality",
   "metadata": {},
   "source": [
    "The same variable you can call simply as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DEP_TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-threshold",
   "metadata": {},
   "source": [
    "Let's try to select 2D parts as in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[3:20, 1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-extra",
   "metadata": {},
   "source": [
    "Pandas will not understand straigth like that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-retro",
   "metadata": {},
   "source": [
    "Here you can select rows and specifying indexes. Notice that sign **:** specifies a range between given values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-power",
   "metadata": {},
   "source": [
    "In case you want to clean the data, you can either select the column, row or to affect the whole dataframe. If you wnat to specify row and column, there are multiple ways to do it. One of the most practical technique is to define by **pd.loc** or **pd.iloc**:\n",
    "- loc gets rows (and/or columns) with particular labels\n",
    "- iloc gets rows (and/or columns) at integer locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3:20,'TIME_HOUR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3:20, 1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-portland",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-abraham",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-1 means I take the last value\n",
    "df.iloc[3:20,[1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-credit",
   "metadata": {},
   "source": [
    "In case you want to replace specified values with different, you can use a replace function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-honey",
   "metadata": {},
   "source": [
    "Lets check the unique values of variable DEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CARRIER'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-remove",
   "metadata": {},
   "source": [
    "We want to replace given values to a more extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TEST_CARRIER'] = df['CARRIER'].copy()\n",
    "df['TEST_CARRIER'] = df['TEST_CARRIER'].replace({'UA':\"UNITED AIRLINES\",\"AA\":\"AMERICAN AIRLINES\"})\n",
    "df['TEST_CARRIER'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-sight",
   "metadata": {},
   "source": [
    "The same result you can achieve in different, simplier way. You can specify which column / indexes you want to affect and with which values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TEST_CARRIER_2'] = df['CARRIER'].copy()\n",
    "df.loc[ df['TEST_CARRIER_2']==\"UA\",'TEST_CARRIER_2'] = \"UNITED AIRLINES\"\n",
    "df.loc[ df['TEST_CARRIER_2']==\"AA\",'TEST_CARRIER_2'] = \"AMERICAN AIRLINES\"\n",
    "df['TEST_CARRIER_2'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-tribute",
   "metadata": {},
   "source": [
    "The natural question comes which method to use since the outcome is the same. If you are more comfortable with one or other method which is easy to track, you should stick with it. pd.replace() method has a clear advantageous which is using json dictionary as an argument. To be more clear, lets say we are not sure which columns to change, we might change the name in the future, so we can write as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_renamed = {'UA':\"UNITED AIRLINES\",\n",
    "                   \"AA\":\"AMERICAN AIRLINES\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TEST_CARRIER'] = df['TEST_CARRIER'].replace(columns_renamed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-cleaning",
   "metadata": {},
   "source": [
    "We are more comfortable to modify a json dictionary instead by trying to identify every affected column in **.loc** function. As well even there is nothing to replace, it will not give an error. In general, **.loc** and **.iloc** are very beneficial since you can clean data in many ways. But Pandas supports a vast of helpful functions, so if you know how to replace **.loc** or **.iloc** with more specific pandas functions which has the main aim for it, you should stick with specific function. A good example was given by pd.replace() function, how to be more effective in tracking and managing code process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-killing",
   "metadata": {},
   "source": [
    "Let's say you want to create a new variable for the dataframe. You can create a new variable from the rest of the values or either the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NEW_VARIABLE'] = 0\n",
    "df['NEW_VARIABLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TOTAL_TIME'] = df['DEP_TIME'] + df['ARR_TIME']\n",
    "df['TOTAL_TIME']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-blackberry",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-compilation",
   "metadata": {},
   "source": [
    "Here you can learn how to detect which values either missing or not. Moreover, how to fill missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-measurement",
   "metadata": {},
   "source": [
    "You can notice that every value show either value is missing (True) or not (False). Moreover, you can select the values which are only positive, since by spectating the whole dataframe of it can look messy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-declaration",
   "metadata": {},
   "source": [
    "We can be more detailed and to create a filter for the dataframe by to filtering out values based on negative values on specified variable. Assuming we want to check which rows has missing CARRIER variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.isna(), 'YEAR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-signal",
   "metadata": {},
   "source": [
    "Seems it is clear, now take a look at variable DEP_TIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['DEP_TIME'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-humidity",
   "metadata": {},
   "source": [
    "Clearly you can see there are missing values. To have a quick look how many missing values are, we can count how many in general are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-implementation",
   "metadata": {},
   "source": [
    "Clearly, the maximum number of rows is 7198, but not all variables has it, which indicates there are missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-guest",
   "metadata": {},
   "source": [
    "Handling the missing values in pandas is easy. You can select either to fill the missing values for the whole dataset or for specific interval. First we want to separate rows with missing values to have a better view how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df[df['DEP_TIME'].isna()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-master",
   "metadata": {},
   "source": [
    "Lets fill DEP_TIME missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing['DEP_TIME'] = df_missing['DEP_TIME'].fillna(\"filled\")\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-kitchen",
   "metadata": {},
   "source": [
    "Moreover, we can fill missing values not only by specific column or row, as well for the whole dataframe. But in this case, we want to fill missing values by the mean of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df_missing.fillna(df.mean())\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-passage",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Join Merge and Concatenate](02-join-merge-and-concatenate.ipynb) | [Contents](Index.ipynb) | [More Operation on Dataframe](04-more-operation-on-dataframe.ipynb) >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
