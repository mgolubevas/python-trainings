{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "associate-liberal",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Intro and Load Data](01-intro-and-load-data.ipynb) | [Contents](Index.ipynb) | [Data Cleaning and Handling Missing Values](03-data-cleaning-and-handling-missing-values.ipynb) >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-legend",
   "metadata": {},
   "source": [
    "## Join Merge and Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-elimination",
   "metadata": {},
   "source": [
    "Pandas provides various facilities for easily combining together Series or DataFrame with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-glass",
   "metadata": {},
   "source": [
    "To be able to test the functions, lets import a dataframe from dwh and excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../Data/airlineDT.csv', sep=',')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv('D_Data_Extension.csv', sep=';') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-vietnam",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-limitation",
   "metadata": {},
   "source": [
    "Similarly as in SQL, Pandas can join, merge or concatenate different dataframe. Since we have two dataframes from db2 and csv, we can merge both of them. Here you can merge both data set by defining HOW (outer, inner, left, right) and ON which variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-exercise",
   "metadata": {},
   "source": [
    "<img src=\"../fig/SQL_pandas.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-research",
   "metadata": {},
   "source": [
    "Now we want to use excel file for grouping with dataframe. We want to match similar ORIGIN data and add only the FULL_ORIGIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df, df_csv, how=\"outer\", on=[\"ORIGIN\"])\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-quantum",
   "metadata": {},
   "source": [
    "You can notice that variable FULL_ORIGIN was merged into DB2 dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-occupation",
   "metadata": {},
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-canadian",
   "metadata": {},
   "source": [
    "Join method is a good way to combine two dataframes with a potentially differently-indexed dataframes. Here is a simple example if you have two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame(\n",
    "     {\"A\": [\"A0\", \"A1\", \"A2\"], \"B\": [\"B0\", \"B1\", \"B2\"]}, index=[\"K0\", \"K1\", \"K2\"]\n",
    "    ) \n",
    "\n",
    "right = pd.DataFrame(\n",
    "     {\"C\": [\"C0\", \"C2\", \"C3\"], \"D\": [\"D0\", \"D2\", \"D3\"]}, index=[\"K0\", \"K2\", \"K3\"]\n",
    "    )\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-gardening",
   "metadata": {},
   "source": [
    "Now we want to join **right** dataframe to the **left** dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = left.join(right)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-track",
   "metadata": {},
   "source": [
    "By the result of the join function, the dataframes joined in **outer** way. In order to join by **inner**, you can define by which method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = left.join(right, how=\"inner\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-tours",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-seafood",
   "metadata": {},
   "source": [
    "The special thing about pandas is you can very easy to concatenate by specifying either by row or by column. In order to properly demonstrate how to do it, lets split the data for a concatenate case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating length of rows, getting a row value which has 50% of data and rounding to integer.\n",
    "row_split=round(len(df)*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[:row_split].copy()\n",
    "df2 = df[row_split:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-indianapolis",
   "metadata": {},
   "source": [
    "Here you will concatenate two dataframes by the row which is given by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1,df2])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-saturn",
   "metadata": {},
   "source": [
    "In case you want to concatenate by the column, you can define axis=1 which states to focus on column. In case there will be missing (non-matching) values, it will replace as missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1,df2], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-brighton",
   "metadata": {},
   "source": [
    "In general, all given ways can be used to manipulate data, where by using different way, as join or concatenate can bring the same result. Moreover, if you want explore more about this part, you can look at the given reference:\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.concat.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-eating",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Intro and Load Data](01-intro-and-load-data.ipynb) | [Contents](Index.ipynb) | [Data Cleaning and Handling Missing Values](03-data-cleaning-and-handling-missing-values.ipynb) >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
